# Load in necessary libraries using library()
library(dplyr)
library(tidyverse)
library(caret)
library(leaps)
library(reshape2)
library(fastDummies) #Create dummy columns easily
library(plyr) # Rename columns
# Import the raw dataset by using read.csv()
url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on Telecom Churn Data/Raw Datasets/churn_clean.csv"
churndata <- read.csv(url, header = TRUE)
# Remove any customer demographic data by indexing
churn_indexed <- churndata[c(20:50)]
# Filter the dataset to only Month-to-Month customers by using dplyr::filter()
churn_filtered <- churn_indexed %>% filter(Contract=='Month-to-month')
# Transform the categorical variables into dummy variable columns by using fastDummies::dummy_cols()
churn_dummies <- dummy_cols(churn_filtered, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
# Index again to remove any unnecessary columns (Contract)
churn_index <- churn_dummies[c(1:17,19:34)]
# Rename any variables with spaces in their name by using plyr::rename()
churn_renamed <- rename(churn_index, replace = c("InternetService_Fiber Optic" = "InternetService_Fiber_Optic"))
churn_renamed <- rename(churn_renamed, replace = c("PaymentMethod_Credit Card (automatic)" = "PaymentMethod_Credit_Card_(automatic)"))
churn_renamed <- rename(churn_renamed, replace = c("PaymentMethod_Electronic Check" = "PaymentMethod_Electronic_Check"))
churn_renamed <- rename(churn_renamed, replace = c("PaymentMethod_Mailed Check" = "PaymentMethod_Mailed_Check"))
# Create a Summary Output of the dataset by using summary()
summary(churn_renamed)
# Create a correlation matrix to help identify potential issues for multicollinearity
cormatrix <- round(cor(churn_renamed),2)
melted_cormatrix <- melt(cormatrix)
ggplot(melted_cormatrix, aes(x = Var1, y= Var2, fill = value)) + geom_tile()
cormatrix[,"Tenure"]
write.csv(cormatrix,"C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on Telecom Churn Data/Explanations/Correlation Matrix/Correlation Matrix.csv", row.names = TRUE)
# Remove Bandwidth_GB_Year from the analysis and dataset by indexing as it is highly correlated with Tenure to avoid multicollinearity.
churn_nomult <- churn_renamed[c(1:6,8:33)]
# Export the prepared dataset
write.csv(churn_nomult, "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on Telecom Churn Data/Cleansed Datasets/Prepped Dataset.csv", row.names = TRUE)
# Create the gross/initial model w/ MultiCollinearity
MLR_GrossModel_Mlt <- lm(Tenure ~ ., churn_renamed)
summary(MLR_GrossModel_Mlt)
# Create the gross/initial model w/o MultiCollinearity
MLR_GrossModel <- lm(Tenure ~ ., churn_nomult)
summary(MLR_GrossModel)
# Use Regression Subsets to find the top 3 variables which impact Tenure
MLR_subsets <- regsubsets(Tenure ~ ., churn_nomult, nvmax = 3)
summary(MLR_subsets)
# Create Univariate visualizations of top 3 independent variables & dependent variable
par(mfrow = c(2,2))
Tenure_hist <- hist(churn_nomult$Tenure)
ChurnYes_hist <- hist(churn_nomult$Churn_Yes)
MonthlyCharge_hist <- hist(churn_nomult$MonthlyCharge)
InternetServiceFiberOptic_hist <- hist(churn_nomult$InternetService_Fiber_Optic)
# Create Bivariate visualizations of top 3 independent variables
par(mfrow=c(1,3))
ChurnYes_boxplot <- boxplot(Tenure ~ Churn_Yes, data = churn_nomult)
MonthlyCharge_boxplot <- plot(Tenure ~ MonthlyCharge, data = churn_nomult)
InternetServiceFiberOptic_boxplot <- boxplot(Tenure ~ InternetService_Fiber_Optic, data = churn_nomult)
# Create the adjusted/reduced model
MLR_AdjustedModel <- lm(Tenure ~ Churn_Yes + MonthlyCharge + InternetService_Fiber_Optic, churn_nomult)
summary(MLR_AdjustedModel)
# Identify the coefficients of the Adjusted Model
coef(MLR_AdjustedModel)
# Create the reduced model with only 2 variables (just for testing)
MLR_Reduced2Model <- lm(Tenure ~ Churn_Yes + MonthlyCharge, churn_nomult)
summary(MLR_Reduced2Model)
# Save and Load Model
model_url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on Telecom Churn Data/Exported Models/TelecomMLRModel.rds"
saveRDS(MLR_Reduced2Model, model_url)
MLR_model <- readRDS(model_url)
# Residual Plots
par(mfrow = c(2,2))
plot(MLR_GrossModel)
plot(MLR_model)
# Load in necessary libraries using library()
library(dplyr)
library(tidyverse)
library(caret)
library(leaps)
library(reshape2)
library(fastDummies) #Create dummy columns easily
library(MLmetrics) #Calculate F1_Score
library(plyr) # Rename columns
# Import the raw dataset using read.csv()
url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Logistic Regression on Telecom Churn Data/Raw Datasets/churn_clean.csv"
churndata <- read.csv(url, header = TRUE)
# Remove customer demographic data by indexing
churn_indexed <- churndata[c(20:50)]
# Transform categorical variables in dummy variable columns by using fastDummies::dummy_cols()
churn_dummies <- dummy_cols(churn_indexed, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
names(churn_dummies)
# Rename any variables with spaces in their names by using plyr::rename()
churn_renamed <- rename(churn_dummies, replace = c("Contract_One year" = "Contract_One_Year"))
churn_renamed <- rename(churn_renamed, replace = c("Contract_Two Year" = "Contract_Two_Year"))
churn_renamed <- rename(churn_renamed, replace = c("InternetService_Fiber Optic" = "InternetService_Fiber_Optic"))
churn_renamed <- rename(churn_renamed, replace = c("PaymentMethod_Credit Card (automatic)" = "PaymentMethod_Credit_Card_(automatic)"))
churn_renamed <- rename(churn_renamed, replace = c("PaymentMethod_Electronic Check" = "PaymentMethod_Electronic_Check"))
churn_renamed <- rename(churn_renamed, replace = c("PaymentMethod_Mailed Check" = "PaymentMethod_Mailed_Check"))
# Normalize all variables by using caret::preProcess()
preproc <- preProcess(churn_renamed, method = c("range"))
churn_norm <- predict(preproc, churn_renamed)
summary(churn_norm)
# Create a correlation matrix and heatmap to identify multicollinearity by using cor(), ggplot2::ggplot(), and reshape2::melt()
cormatrix <- round(cor(churn_norm),2)
melted_cormatrix <- melt(cormatrix)
ggplot(melted_cormatrix, aes(x = Var1, y= Var2, fill = value)) + geom_tile()
cormatrix[,"Churn_Yes"]
write.csv(cormatrix,"C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Logistic Regression on Telecom Churn Data/Explanations/Correlation Matrix/Correlation Matrix.csv", row.names = TRUE)
# Remove Bandwidth_GB_Year from analysis as it is highly correlated with Tenure
churn_norm <- churn_norm[c(1:6,8:35)]
# Export the prepared dataset as a .csv file using write.csv()
write.csv(churn_norm,"C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Logistic Regression on Telecom Churn Data/Cleansed Datasets/Prepped Dataset.csv", row.names = FALSE)
# Create the Gross "Initial" Model
LG_GrossModel <- glm(Churn_Yes ~ ., data = churn_norm, family = "binomial")
summary(LG_GrossModel)
# Subset Regression to identify the top 5 variables affecting Churn using leaps::regsubsets()
subsets <- regsubsets(Churn_Yes ~ ., data = churn_norm, nvmax = 5)
summary(subsets)
# Create Univariate Distributions using histograms
par(mfrow = c(2,3))
InternetServiceFiberOptic_hist <- hist(churn_norm$InternetService_Fiber_Optic)
ContractOneYear_hist <- hist(churn_norm$Contract_One_Year)
ContractTwoYear_hist <- hist(churn_norm$Contract_Two_Year)
Tenure_hist <- hist(churn_norm$Tenure)
MonthlyCharge_hist <- hist(churn_norm$MonthlyCharge)
ChurnYes_hist <- hist(churn_norm$Churn_Yes)
# Create Bivariate Distrbutions using boxplot()
par(mfrow = c(2,3))
Tenure_boxplot <- boxplot(Tenure ~ Churn_Yes, data = churn_norm)
MonthlyCharge_boxplot <- boxplot(MonthlyCharge ~ Churn_Yes, data = churn_norm)
InternetServiceFiberOptic_boxplot <- boxplot(InternetService_Fiber_Optic ~ Churn_Yes, data = churn_norm)
ContractOneYear_boxplot <- boxplot(Contract_One_Year~ Churn_Yes, data = churn_norm)
ContractTwoYear_boxplot <- boxplot(Contract_Two_Year~ Churn_Yes, data = churn_norm)
# Reduced Correlation Matrix of only top 5 variables
reduced_data <- churn_norm[c(16,5:6,18:19,22)]
reduced_cormatrix <- round(cor(reduced_data),2)
reduced_cormatrix
# Create the Adjusted "Reduced" Model based on the 5 variables found above
LG_AdjustedModel <- glm(Churn_Yes ~ Tenure + MonthlyCharge + Contract_One_Year + Contract_Two_Year + InternetService_Fiber_Optic, churn_norm, family = "binomial")
summary(LG_AdjustedModel)
# Extract Coefficients of the Adjusted Model using coef()
coef(LG_AdjustedModel)
# Create the 4-variable reduced model based on the subsets found
LG_Reduced4Model <- glm(Churn_Yes ~ Tenure + MonthlyCharge + Contract_One_Year + Contract_Two_Year, churn_norm, family = "binomial")
summary(LG_Reduced4Model)
# Save and Load 5-variable Model
var5_model_url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Logistic Regression on Telecom Churn Data/Exported Models/TelecomLogisticRegressionModel5Variables.rds"
saveRDS(LG_AdjustedModel, var5_model_url)
LG_AdjustedModel <- readRDS(var5_model_url)
# Save and Load 4-variable Model
var4_model_url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Logistic Regression on Telecom Churn Data/Exported Models/TelecomLogisticRegressionModel4Variables.rds"
saveRDS(LG_Reduced4Model, var4_model_url)
LG_Reduced4Model <- readRDS(var4_model_url)
# Confusion Matrix for Gross Model with all variables
LGmodelGPred <- round(predict(LG_GrossModel, churn_norm, type = "response"))
LGmodelG <- confusionMatrix(as.factor(LGmodelGPred), as.factor(churn_norm$Churn))
LGmodelG
# Confusion Matrix for Adjusted Model with all variables
LGmodelAPred <- round(predict(LG_AdjustedModel, churn_norm, type = "response"))
LGmodelA <- confusionMatrix(as.factor(LGmodelAPred), as.factor(churn_norm$Churn_Yes))
LGmodelA
# Confusion Matrix for Reduced-4 variable Model with all variables
LGmodel4Pred <- round(predict(LG_Reduced4Model, churn_norm, type = "response"))
LGmodel4 <- confusionMatrix(as.factor(LGmodel4Pred), as.factor(churn_norm$Churn_Yes))
LGmodel4
# Calculate F1_Score of Gross Model
pred <- ifelse(LG_GrossModel$fitted.values < 0.5, 0, 1)
F1_Score(y_pred = pred, y_true = churn_norm$Churn_Yes, positive = "0")
# Calculate F1_Score of Adjusted Model
pred <- ifelse(LG_AdjustedModel$fitted.values < 0.5, 0, 1)
F1_Score(y_pred = pred, y_true = churn_norm$Churn_Yes, positive = "0")
# Calculate F1_Score of Reduced-4 variable Model
pred <- ifelse(LG_Reduced4Model$fitted.values < 0.5, 0, 1)
F1_Score(y_pred = pred, y_true = churn_norm$Churn_Yes, positive = "0")
# Install necessary packages
install.packages("readxl")
install.packages("tidyverse")
#Load all necessary packages
library(tidyverse)
library(readxl)
library(dplyr)
library(tidyr)
library(modelr)
library(ggplot2)
# Import the raw dataset using readxl::read_excel
url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on PA Population Data/Raw Datasets/nst-est2019-alldata.xlsx"
raw_data <- read_excel(url)
# Cleanse the data for Pennsylvania 2010 - 2019 using dplyr::select & dplyr::filter
data <- raw_data %>% select(NAME, "2010":"2019")
data <- filter(data, NAME == "Pennsylvania")
# Remove the NAME column using dplyr::select
data2 <- data %>% select("2010":"2019")
# Create a dataframe from data2 using data.frame
# t(data2) is used to transpose the data from horizontal to vertical
# 2010:2019 creates a column of Years
df2<-data.frame(x=2010:2019, y=t(data2))
rownames(df2) <- NULL #This resets the rownames
# Export cleansed dataset
write.csv(df2, "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on PA Population Data/Cleansed Datasets/Prepped Dataset.csv")
# Create your linear regression model using modelr::lm()
df2_mod<- lm(y ~ x, data = df2)
coef(df2_mod)
# Save and Load Model
model_url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on PA Population Data/Exported Models/PAPopulationLRModel.rds"
saveRDS(df2_mod, model_url)
df2_mod <- readRDS(model_url)
# Create a grid to add your predictions for plotting using add_predictions()
grid <- df2 %>% data_grid(x)
grid <- grid %>% add_predictions(df2_mod)
# Plot the grid using ggplot2::ggplot()
ggplot(df2, aes(x)) +
geom_point(aes(y = y)) +
geom_line(aes(y = pred), data = grid, colour = "blue", size = 1)
# Add the residuals to your dataframe using add_residuals()
df2 <- df2 %>% add_residuals(df2_mod)
# Plot the residuals to view the frequency using geom_freqpoly()
ggplot(df2, aes(resid)) +
geom_freqpoly()
# Create a summary of your data using summary()
summary(df2)
# Predict the population for the next five years using predict()
five_year_pred <- data.frame (x=2020:2025)
rownames(five_year_pred) <- c(2020:2025)
predict(df2_mod,newdata = five_year_pred)
install.packages("readxl")
#Load all necessary packages
library(tidyverse)
library(readxl)
library(dplyr)
library(tidyr)
library(modelr)
library(ggplot2)
# Import the raw dataset using readxl::read_excel
url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on PA Population Data/Raw Datasets/nst-est2019-alldata.xlsx"
raw_data <- read_excel(url)
# Cleanse the data for Pennsylvania 2010 - 2019 using dplyr::select & dplyr::filter
data <- raw_data %>% select(NAME, "2010":"2019")
data <- filter(data, NAME == "Pennsylvania")
# Remove the NAME column using dplyr::select
data2 <- data %>% select("2010":"2019")
# Create a dataframe from data2 using data.frame
# t(data2) is used to transpose the data from horizontal to vertical
# 2010:2019 creates a column of Years
df2<-data.frame(x=2010:2019, y=t(data2))
rownames(df2) <- NULL #This resets the rownames
# Export cleansed dataset
write.csv(df2, "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on PA Population Data/Cleansed Datasets/Prepped Dataset.csv")
# Create your linear regression model using modelr::lm()
df2_mod<- lm(y ~ x, data = df2)
coef(df2_mod)
# Save and Load Model
model_url <- "C:/Users/tedda/Desktop/Data Science Portfolio/Machine Learning/Supervised Learning/Regression/Linear Regression on PA Population Data/Exported Models/PAPopulationLRModel.rds"
saveRDS(df2_mod, model_url)
df2_mod <- readRDS(model_url)
# Create a grid to add your predictions for plotting using add_predictions()
grid <- df2 %>% data_grid(x)
grid <- grid %>% add_predictions(df2_mod)
# Plot the grid using ggplot2::ggplot()
ggplot(df2, aes(x)) +
geom_point(aes(y = y)) +
geom_line(aes(y = pred), data = grid, colour = "blue", size = 1)
# Add the residuals to your dataframe using add_residuals()
df2 <- df2 %>% add_residuals(df2_mod)
# Plot the residuals to view the frequency using geom_freqpoly()
ggplot(df2, aes(resid)) +
geom_freqpoly()
# Create a summary of your data using summary()
summary(df2)
# Predict the population for the next five years using predict()
five_year_pred <- data.frame (x=2020:2025)
rownames(five_year_pred) <- c(2020:2025)
predict(df2_mod,newdata = five_year_pred)
